Manaul Testing 


------>>>>>What is the difference between Test matrix and Traceability matrix?
Test Matrix: Test matrix is used to capture actual quality, effort, the plan, resources and time required to capture all phases of software testing
Traceability Matrix: Mapping between test cases and customer requirements is known as Traceability Matrix


** What are the different stages of an Automation test ???
Test Planning: Define the goals and scope of automation.
Test Design: Design the structure and test cases.
Test Development: Write the automation scripts.
Test Execution: Run the automated tests.
Test Reporting: Analyze the results and share reports.
Test Maintenance: Update scripts based on changes in the application.
Test Optimization: Improve the speed and effectiveness of tests.
Test Analysis and Feedback: Evaluate and optimize the automation process.

@* Test Stratergy Document -- This documentation for Organization level -- Give the overall Proccess of testing
@* Test Plan --- Project Level Document

Scope: Define in-scope and out-of-scope items.
Objectives: Validate functional requirements.
Test Types: Functional Testing.
Test Environment:Test data preparation.
Entry and Exit Criteria:
Deliverables:
Risks and Assumptions:
Risks: Delayed builds, incomplete requirements.
Assumptions: Stable test environments, timely documentation.
Roles and Responsibilities:
Schedule:
Approval:
Stakeholders sign off on the plan.
These points ensure a concise and actionable test plan for manual testing. Let me know if you need help expanding any section!

Static code analysis----->
Static code analysis is a process of examining the source code of a 
program without executing it to detect potential bugs, security vulnerabilities, 
code smells, and ensure adherence to coding standards.

Clean Code Principles (including SOLID and DRY)
clean code principles to demonstrate how you write maintainable, readable, and efficient code. 
These principles help create code that is easier to understand, modify, and extend over time. 


Sprint Velocity in Agile:
Sprint Velocity is a metric used in Agile project management to measure the amount of work a team can 
complete during a single sprint. 

************* SOLID Principles ***********************
SOLID principles in Java are a set of design principles aimed at creating maintainable, scalable, and robust software.

1. Single Responsibility Principle (SRP): Class should have one responsibility.
A class with multiple responsibilities becomes hard to maintain and test because changes in one responsibility might affect others
example:
class UserService {
    void createUser(String username) {
        // Logic to create a user
    }
}

class EmailService {
    void sendEmail(String email) {
        // Logic to send email
    }
}

2.Open/Closed Principle (OCP)
Definition: A class should be open for extension but closed for modification.

Problem: Modifying existing code for new functionality can introduce bugs and requires retesting.
Solution: Use abstractions like interfaces or inheritance to add new functionality without modifying existing code.

3.Liskov Substitution Principle (LSP)
This means that if a program is using a base class, you should be able to replace it with any subclass of that 
base class without the program malfunctioning. The subclass must adhere to the expectations (behavioral contracts) set by the base class.

4.Interface Segregation Principle (ISP)
A class should not be forced to implement interfaces it doesn't use.

Problem: A large interface with methods irrelevant to some implementing classes leads to unnecessary code and complexity.
Solution: Break down large interfaces into smaller, more specific ones.

5.Dependency Inversion Principle (DIP)
Definition: High-level modules should not depend on low-level modules; both should depend on abstractions.

Problem: Tight coupling between high-level and low-level modules makes the code harder to test and maintain.
Solution: Use interfaces to decouple the modules.

Benefits of SOLID Principles
Maintainability: Code is easier to understand and modify.
Scalability: New features can be added without modifying existing code.
Testability: Decoupled and modular code is easier to test.
Readability: Clean and organized code with clear responsibilities.

Entry Criteria -> Conditions that must be met before a testing phase or process begins., ensures testing can start without interruptions.
Exit  Criteria -> Conditions that must be satisfied to conclude a testing phase or process, objectives are met and results are acceptable for project delivery or the next phase.

Manual Testing:
Entry Criteria -> Requirements Clarity, Test Plan and Test Cases, Test Environment, Build Availability, Test Data,Defect Management Tool
Exit  Criteria -> Test Case Execution, Defect Resolution,Test Results Documentation,Requirement Coverage,Sign-Off

Automation Testing:
Entry Criteria ->  Stable Application Build, Automation Framework ,Automation Tools ,Test Environment ,Script Readiness
Exit  Criteria -> Script Execution Completion,Defect Verification,Test Coverage,Regression Results,Reports Generation,Framework Stability,Stakeholder Approval


Priority vs. Severity

Priority: How urgent it is to fix a bug based on project needs.
Severity: How much the bug impacts the user or system.



****************   How do you manage and track bugs through the testing lifecycle?  *********************


New: A bug is identified and logged for the first time.
Assigned: The bug is reviewed and assigned to a developer or a team for resolution.
In Progress: The developer is actively working on resolving the bug.
Resolved: The developer fixes the bug and marks it as resolved.
Verified: The QA team retests the fix and verifies the resolution.
Closed: The bug is marked as closed if the fix is verified successfully.
Reopened (if applicable): If the issue persists or reoccurs, the bug is reopened and reentered into the lifecycle.

Create a detailed bug ticket with the following details:
1)Title
2) Description
3) Severity
4) Priority
5) Attachments
Categorize andÂ PrioritizeÂ Bugs


******************************** DOR and DOD ***************************

** Definition of Ready (DOR) ðŸ“Œ
The DOR ensures that a user story or task is fully prepared before being picked up for development. It defines the minimum criteria that must be met before a task enters a sprint.

Key Points of DOR:
âœ… The user story is well-defined and clear.
âœ… Acceptance criteria are written and understood.
âœ… Dependencies are identified and resolved.
âœ… Necessary mockups, designs, and API contracts are available.
âœ… The story is estimated and approved by the team.

** Definition of Done (DOD) âœ…
The DOD ensures that a task or user story is fully completed and meets quality standards before being considered "done".

Key Points of DOD:
âœ… Code is written, reviewed, and merged.
âœ… Unit tests and automation tests are implemented and passed.
âœ… The functionality is tested in a staging environment.
âœ… No major bugs or issues exist.
âœ… The feature is deployed and documented.

***************  Test Strategy  *********************
Definition: A high-level document that defines the approach, objectives, and overall guidelines for testing activities
A test strategy is typically used by QA managers or senior stakeholders to standardize 
testing processes across teams and ensure alignment with organizational goals.
Key Components of a Test Strategy:
Testing Objectives
Testing Scope
Testing Approach
Tools and Technologies
Test Environment
Risk Management
Metrics and Reporting

****************** Test Plan  **********************
Definition: A detailed document that outlines and provide a roadmap for testing activities, ensuring that all necessary tasks are completed.
A test plan is typically created by the QA lead or test manager for a specific release of a product,
 detailing the step-by-step activities for testing.
Key Components of a Test Plan
Test Objectives
Test Scope
Test Deliverables
Testing Schedule
Roles and Responsibilities
Test Environment Requirements
Entry and Exit Criteria
Risks and Contingencies

*************** Entry and Exit Criteria *****************
Entry Criteria:
Entry criteria are the conditions that must be met before automation testing can begin. These conditions help ensure that the testing process is 
efficient and avoids wasted effort.

Exit Criteria:
Exit criteria are the conditions that must be fulfilled before the automation testing process can be concluded. 
These ensure that testing objectives are met and the application is ready for the next stage.

******************* Regression Testing anf Retesting **********************

Regression Testing:
Regression testing is performed to ensure that new changes, such as enhancements, bug fixes, or updates, have not adversely affected
the existing functionality of the application.
Its is Performed After changes like bug fixes, enhancements, or updates.
Performed multiple times throughout development.

Objective:
Verify that the application works as expected after changes.
Ensure stability of the unchanged parts of the system.
Scope: Broad, covering both affected and unaffected areas.	

Retesting:
Retesting is performed to verify that specific bugs or issues reported earlier have been fixed.
It is performed After the reported defects are fixed.
Performed only after defect fixes.

Objective:
Confirm that the reported defect is resolved.
Validate the exact change without considering the surrounding system.
Scope: Narrow, focused on specific failed test cases.

*********************** Test Document  **************************
test document provides a structured approach to managing and executing the testing lifecycle for a software application. 
It outlines the test strategy, scope, objectives, entry and exit criteria, test cases, and deliverables.


************************ Time estimation *********************
Time estimation is the process of predicting the duration required to complete a task, activity, or project. 
It is essential for planning, resource allocation, and setting realistic expectations. 
Accurate time estimation involves understanding the scope, complexity, and dependencies of tasks.

Steps for Time Estimation:
1)Understand the Scope
2)Break Down Tasks
3)Assign Effort
4)Add Buffers
5)Validate Estimates

********************** Exploratory Testing ********************
Exploratory testing is a type of software testing where testers simultaneously design, execute, and learn about the system under 
test without predefined test cases. It emphasizes the tester's creativity, experience, and intuition to identify issues that might not be 
covered by formal testing methods.

-----How to Perform Exploratory Testing
1) Understand the Application
2) Define Charters
3) Explore and Test
4) Document Findings
5)Review and Repeat

*******************************************************************************************************************************

What is SDLC ? 
1.Planning:
	In this initial phase we define the project's scope, goals, and objectives, as well as identify the resources and 
	tools needed for the project.
2. Requirements Analysis:
	In this phase, we gather and analyzes the requirements from stakeholders to understand what the software should
	do and how it should function.
3. Design:
	We create the software architecture and design test cases
4. Implementation:
	In this phase we start with writing the code and building the software based on the design specifications.
5. Testing:
	During this phase, the software is rigorously tested to identify and fix bugs and we ensure that it meets the 
	requirements.
6. Deployment:
	Once the software is tested and ready, it's deployed to the target environment and made available to users.
7. Maintenance:
	After deployment, the software is maintained to ensure it continues to function correctly and to address any 
	issues that arise.


********************************************************************************************************* 

										STLC
													
1. Requirement Analysis:
in t phase involves understanding the product requirements, including both functional and non-functional requirements, to determine what needs to be tested. 
2. Test Planning:
This phase focuses on creating a test strategy, including defining the scope, objectives, resources, and schedule for the testing process. 
3. Test Case Development:
In this phase, test cases are created to cover different scenarios and conditions, ensuring thorough testing. 
4. Test Environment Setup:
This phase involves setting up the necessary hardware, software, and network resources to create a suitable environment for executing the tests. 
5. Test Execution:
This is the core phase where the test cases are executed, and the results are recorded. 
6. Defect Reporting:
Any issues or defects found during test execution are documented and reported, providing feedback to the development team. 
7. Test Closure:
This final phase involves evaluating the entire testing process, documenting the results, and identifying lessons learned to improve future testing efforts. 

************************* Severity and Priority *************************************
Severity (Impact of the bug): Describes how serious the bug is in terms of the application's functionality.
Usually set by the Tester
Types of Severity:
Critical â€“ System crash, data loss, no workaround.
High â€“ Major functionality broken, no workaround.
Medium â€“ Minor functionality not working properly, workaround exists.
Low â€“ Cosmetic issues, spelling mistakes, UI misalignments.

Priority (Urgency to fix the bug): Describes how soon the bug should be fixed from a business point of view.
Usually set by the Project Manager/Product Owner/Developer.
Types of Priority:
High â€“ Needs to be fixed immediately.
Medium â€“ Should be fixed in the normal development cycle.
Low â€“ Can be fixed later; not urgent.			Priority			Example


Severity			Priority			Example
High				High				Login button not working in production.
High				Low					App crashes when a rare edge case occurs.
Low					High				Company logo is incorrect on homepage.
Low					Low					Typo in the "About Us" section.




